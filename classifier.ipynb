{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Div</th>\n",
       "      <th>Date</th>\n",
       "      <th>HomeTeam</th>\n",
       "      <th>AwayTeam</th>\n",
       "      <th>FTHG</th>\n",
       "      <th>FTAG</th>\n",
       "      <th>FTR</th>\n",
       "      <th>HTHG</th>\n",
       "      <th>HTAG</th>\n",
       "      <th>HTR</th>\n",
       "      <th>...</th>\n",
       "      <th>BbAv&lt;2.5</th>\n",
       "      <th>BbAH</th>\n",
       "      <th>BbAHh</th>\n",
       "      <th>BbMxAHH</th>\n",
       "      <th>BbAvAHH</th>\n",
       "      <th>BbMxAHA</th>\n",
       "      <th>BbAvAHA</th>\n",
       "      <th>PSCH</th>\n",
       "      <th>PSCD</th>\n",
       "      <th>PSCA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/16</td>\n",
       "      <td>Burnley</td>\n",
       "      <td>Swansea</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1.61</td>\n",
       "      <td>32</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.06</td>\n",
       "      <td>1.86</td>\n",
       "      <td>1.81</td>\n",
       "      <td>2.79</td>\n",
       "      <td>3.16</td>\n",
       "      <td>2.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/16</td>\n",
       "      <td>Crystal Palace</td>\n",
       "      <td>West Brom</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1.52</td>\n",
       "      <td>33</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.07</td>\n",
       "      <td>2.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.25</td>\n",
       "      <td>3.15</td>\n",
       "      <td>3.86</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/16</td>\n",
       "      <td>Everton</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.77</td>\n",
       "      <td>32</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.91</td>\n",
       "      <td>1.85</td>\n",
       "      <td>2.09</td>\n",
       "      <td>2.00</td>\n",
       "      <td>3.64</td>\n",
       "      <td>3.54</td>\n",
       "      <td>2.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/16</td>\n",
       "      <td>Hull</td>\n",
       "      <td>Leicester</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1.67</td>\n",
       "      <td>31</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2.35</td>\n",
       "      <td>2.26</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.67</td>\n",
       "      <td>4.68</td>\n",
       "      <td>3.50</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E0</td>\n",
       "      <td>13/08/16</td>\n",
       "      <td>Man City</td>\n",
       "      <td>Sunderland</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.48</td>\n",
       "      <td>34</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.81</td>\n",
       "      <td>1.73</td>\n",
       "      <td>2.20</td>\n",
       "      <td>2.14</td>\n",
       "      <td>1.25</td>\n",
       "      <td>6.50</td>\n",
       "      <td>14.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Liverpool</td>\n",
       "      <td>Wolves</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.31</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>1.98</td>\n",
       "      <td>1.91</td>\n",
       "      <td>2.01</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.32</td>\n",
       "      <td>5.89</td>\n",
       "      <td>9.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Man United</td>\n",
       "      <td>Cardiff</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.95</td>\n",
       "      <td>21</td>\n",
       "      <td>-2.00</td>\n",
       "      <td>2.52</td>\n",
       "      <td>2.32</td>\n",
       "      <td>1.72</td>\n",
       "      <td>1.64</td>\n",
       "      <td>1.30</td>\n",
       "      <td>6.06</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>Huddersfield</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.29</td>\n",
       "      <td>22</td>\n",
       "      <td>-1.50</td>\n",
       "      <td>2.27</td>\n",
       "      <td>2.16</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.73</td>\n",
       "      <td>1.37</td>\n",
       "      <td>5.36</td>\n",
       "      <td>8.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Tottenham</td>\n",
       "      <td>Everton</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>D</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>2.07</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.13</td>\n",
       "      <td>2.08</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.91</td>\n",
       "      <td>3.81</td>\n",
       "      <td>4.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>E0</td>\n",
       "      <td>12/05/2019</td>\n",
       "      <td>Watford</td>\n",
       "      <td>West Ham</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>A</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>A</td>\n",
       "      <td>...</td>\n",
       "      <td>2.44</td>\n",
       "      <td>19</td>\n",
       "      <td>-0.50</td>\n",
       "      <td>2.25</td>\n",
       "      <td>2.19</td>\n",
       "      <td>1.78</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.11</td>\n",
       "      <td>3.86</td>\n",
       "      <td>3.41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1140 rows Ã— 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Div        Date        HomeTeam      AwayTeam  FTHG  FTAG FTR  HTHG  \\\n",
       "0     E0    13/08/16         Burnley       Swansea     0     1   A     0   \n",
       "1     E0    13/08/16  Crystal Palace     West Brom     0     1   A     0   \n",
       "2     E0    13/08/16         Everton     Tottenham     1     1   D     1   \n",
       "3     E0    13/08/16            Hull     Leicester     2     1   H     1   \n",
       "4     E0    13/08/16        Man City    Sunderland     2     1   H     1   \n",
       "...   ..         ...             ...           ...   ...   ...  ..   ...   \n",
       "1135  E0  12/05/2019       Liverpool        Wolves     2     0   H     1   \n",
       "1136  E0  12/05/2019      Man United       Cardiff     0     2   A     0   \n",
       "1137  E0  12/05/2019     Southampton  Huddersfield     1     1   D     1   \n",
       "1138  E0  12/05/2019       Tottenham       Everton     2     2   D     1   \n",
       "1139  E0  12/05/2019         Watford      West Ham     1     4   A     0   \n",
       "\n",
       "      HTAG HTR  ... BbAv<2.5  BbAH  BbAHh  BbMxAHH  BbAvAHH  BbMxAHA  BbAvAHA  \\\n",
       "0        0   D  ...     1.61    32  -0.25     2.13     2.06     1.86     1.81   \n",
       "1        0   D  ...     1.52    33  -0.50     2.07     2.00     1.90     1.85   \n",
       "2        0   H  ...     1.77    32   0.25     1.91     1.85     2.09     2.00   \n",
       "3        0   H  ...     1.67    31   0.25     2.35     2.26     2.03     1.67   \n",
       "4        0   H  ...     2.48    34  -1.50     1.81     1.73     2.20     2.14   \n",
       "...    ...  ..  ...      ...   ...    ...      ...      ...      ...      ...   \n",
       "1135     0   H  ...     2.31    22  -1.50     1.98     1.91     2.01     1.95   \n",
       "1136     1   A  ...     2.95    21  -2.00     2.52     2.32     1.72     1.64   \n",
       "1137     0   H  ...     2.29    22  -1.50     2.27     2.16     1.80     1.73   \n",
       "1138     0   H  ...     2.07    19  -0.50     2.13     2.08     1.85     1.80   \n",
       "1139     2   A  ...     2.44    19  -0.50     2.25     2.19     1.78     1.72   \n",
       "\n",
       "      PSCH  PSCD   PSCA  \n",
       "0     2.79  3.16   2.89  \n",
       "1     2.25  3.15   3.86  \n",
       "2     3.64  3.54   2.16  \n",
       "3     4.68  3.50   1.92  \n",
       "4     1.25  6.50  14.50  \n",
       "...    ...   ...    ...  \n",
       "1135  1.32  5.89   9.48  \n",
       "1136  1.30  6.06   9.71  \n",
       "1137  1.37  5.36   8.49  \n",
       "1138  1.91  3.81   4.15  \n",
       "1139  2.11  3.86   3.41  \n",
       "\n",
       "[1140 rows x 65 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "NUM_CLASSES = 3\n",
    "NUM_FEATS = 3\n",
    "PREV_GAMES = 5\n",
    "weight = np.array([.05, .1, .2, .3, .35])\n",
    "#weight = [.15,.35,.5]\n",
    "#weight = [.01,.04,.05,.1,.2,.3,.3]\n",
    "dir_name = os.getcwd()\n",
    "datasets = []\n",
    "data_full = pd.DataFrame()\n",
    "for suffix in ['16-17', '17-18', '18-19']:\n",
    "    csv = dir_name + '/data/match_stats' +'_'+ suffix + '.csv' \n",
    "    dat = pd.read_csv(csv)\n",
    "    datasets.append(dat)\n",
    "    data_full = pd.concat((data_full, dat)).reset_index(drop=True)\n",
    "data_full\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84 109 187\n",
      "99 108 173\n",
      "71 128 181\n"
     ]
    }
   ],
   "source": [
    "# get net scores\n",
    "for data in datasets:\n",
    "    data['goal_diff'] = data['FTHG'] - data['FTAG']\n",
    "    data['shot_diff'] = data['HST'] - data['AST']\n",
    "    data['corner_diff'] = data['HC'] - data['AC']\n",
    "\n",
    "    print(data[data['FTR'] == 'D'].shape[0], data[data['FTR'] == 'A'].shape[0], data[data['FTR'] == 'H'].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.37070243, -0.1958627 ],\n",
       "       [ 0.37070243,  1.        ,  0.72807928],\n",
       "       [-0.1958627 ,  0.72807928,  1.        ]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counter = {}\n",
    "res = {}\n",
    "\n",
    "def update_team_data(team, raw_dat, results, data_vec, is_away):\n",
    "    '''\n",
    "    Builds dictionary that maps a team to its weighted average score in three categories over Prev_Games.\n",
    "    \n",
    "    Parameters:\n",
    "    team (str): team name\n",
    "    raw_dat (dic): dictionary that maps a team its raw data over the past Prev_games\n",
    "    results (dic): maps a team to its weighted average (over Prev_GAMES) score in three categories\n",
    "    data_vec (np.array): the raw data. Columns 2-4 and 62-65 in the orginial dataframe.\n",
    "    is_away (bool): Since the data is of the form Home-Away, we must reverse the sign when computing the\n",
    "                    score of the away team.\n",
    "    \n",
    "    '''\n",
    "    if is_away:\n",
    "        sgn = -1\n",
    "    else:\n",
    "        sgn = 1\n",
    "    if team not in raw_dat:\n",
    "        raw_dat[team] = sgn * data_vec\n",
    "    elif raw_dat[team].shape[0] < PREV_GAMES:\n",
    "        raw_dat[team] = np.vstack((raw_dat[team], sgn * data_vec))\n",
    "    else:\n",
    "        results[team] = dict(zip(['goal', 'shot', 'corner'], np.average(raw_dat[team].astype('float'), axis=0, weights=weight)))\n",
    "        raw_dat[team] = np.vstack((raw_dat[team][1:,], sgn * data_vec))\n",
    "   \n",
    "    return results\n",
    "        \n",
    "\n",
    "\n",
    "def get_avg_diff(row, dic, results):\n",
    "    '''\n",
    "    Creates a list containing the difference between the home team and the away team in\n",
    "    the three categories from the results dictionary\n",
    "    \n",
    "    Parameters:\n",
    "    row (series): A row of the form (home team name, away team name, goal diff, shot diff, corner diff)\n",
    "    dic: Dictionary that maps a team its raw data over the past Prev_games\n",
    "    results (dic): Maps a team to its weighted average (over Prev_GAMES) score in three categories\n",
    "    \n",
    "    returns:\n",
    "    diff (lst): list of length 3 containing the difference between the home team and the away team in\n",
    "    the three categories from the results dictionary\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    update_team_data(row[0], dic, results, row[2:5], False)\n",
    "    res = update_team_data(row[1], dic, results, row[2:5], True)\n",
    "    #print(res.keys())\n",
    "    if row[0] in res and row[1] in res:\n",
    "        diff = []\n",
    "        for key in results[row[0]].keys():\n",
    "            diff.append(results[row[0]][key] - results[row[1]][key])\n",
    "            \n",
    "        return diff\n",
    "    \n",
    "    return [0,0,0]\n",
    "\n",
    "\n",
    "\n",
    "#Create feature matrix\n",
    "X_mat = pd.DataFrame()\n",
    "y = pd.DataFrame()\n",
    "for data in datasets:\n",
    "    X_mat = pd.concat((X_mat, data.iloc[:,np.r_[2:4, 62:65]].apply(\n",
    "        get_avg_diff, axis=1, dic=counter, results=res, result_type='expand').iloc[10 * PREV_GAMES:,].reset_index(drop=True))).reset_index(drop=True)\n",
    "    label_encoder = preprocessing.LabelEncoder()\n",
    "    y = pd.concat((y, pd.DataFrame(label_encoder.fit_transform(data.iloc[10 * PREV_GAMES:,6].reset_index(drop=True))))).reset_index(drop=True)\n",
    "X_mat.columns = ['goals', 'shots', 'corners']\n",
    "y.columns = ['Result']\n",
    "np.corrcoef(X_mat.T)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split data into training, validation, and test sets\n",
    "\n",
    "tr, val, tst = np.split(pd.concat((X_mat,y),axis=1).sample(frac=1, random_state=42),\n",
    "                         [int(len(X_mat) * .6), int(len(X_mat) * .8)])\n",
    "X_tr = tr.iloc[:,:3]\n",
    "y_tr = tr.iloc[:,3]\n",
    "X_val = val.iloc[:,:3]\n",
    "y_val = val.iloc[:,3]\n",
    "X_tst = tst.iloc[:,:3]\n",
    "y_tst = tst.iloc[:,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_hyperparams(mod, Xtr, ytr, Xval, yval, param_grid, fit_param_dic):\n",
    "    '''\n",
    "    Fits model for each element in the cartesian product of the lists of possible values of each parameter\n",
    "    given by the param_grid. Then selects the best model based on the validation accuracy.\n",
    "    \n",
    "    Parameters:\n",
    "    mod (obj): A multiclass classifier\n",
    "    Xtr (np.array): training data\n",
    "    ytr (np.array): 1D array of training labels\n",
    "    Xval (np.array): validation data\n",
    "    yval (np.array): 1D array of validation labels\n",
    "    param_grid (dic): maps each parameter to a list of values to be tested\n",
    "    fit_param_dic (dic): used to implement early stopping for xgboost. Is an empty dictionary for all other classifiers\n",
    "    \n",
    "    Returns:\n",
    "    validation_scores (dic): maps a given combination of parameters to the validation score for that model\n",
    "    best_params_dic (dic): maps the parameter to its optimals value\n",
    "    \n",
    "    \n",
    "    '''\n",
    "    validation_scores = {}\n",
    "    keys, vals = zip(*sorted(param_grid.items()))\n",
    "    for it, params in enumerate(itertools.product(*vals)):\n",
    "        #print(dict(zip(keys, params)))\n",
    "        if it % 50 == 0:\n",
    "            print(it, params)\n",
    "        mod.set_params(**dict(zip(keys, params)))\n",
    "        pipe = Pipeline(steps=[('scaler', preprocessing.StandardScaler()), ('clf', mod)])\n",
    "        pipe.fit(Xtr, ytr, **fit_param_dic)\n",
    "        validation_scores[params] = log_loss(y_val, pipe.predict_proba(X_val), labels=y_val)\n",
    "    best_params = min(validation_scores, key=validation_scores.get)\n",
    "    best_params_dic = dict(zip(keys, best_params))\n",
    "    \n",
    "    return validation_scores, best_params_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 (0.01, 0, 0, 2, 7, 500, 3, 'multi:softmax', 0.7)\n",
      "{'eta': 0.01, 'gamma': 0, 'lambda': 0, 'max_depth': 2, 'min_child_weight': 7, 'n_estimators': 500, 'num_class': 3, 'objective': 'multi:softmax', 'subsample': 0.7}\n",
      "0 (1.0, 0.001, 'rbf', 1)\n",
      "{'C': 1.0, 'gamma': 0.001, 'kernel': 'rbf', 'probability': 1}\n",
      "0 (0.001, 'multinomial', 'sag')\n",
      "50 (0.0015863565335085897, 'multinomial', 'sag')\n",
      "100 (0.002516527051405392, 'multinomial', 'sag')\n",
      "150 (0.003992109129748053, 'multinomial', 'sag')\n",
      "200 (0.006332908400455114, 'multinomial', 'sag')\n",
      "250 (0.010046250617173407, 'multinomial', 'sag')\n",
      "300 (0.015936935303817745, 'multinomial', 'sag')\n",
      "350 (0.025281661443314993, 'multinomial', 'sag')\n",
      "400 (0.04010572880855496, 'multinomial', 'sag')\n",
      "450 (0.06362198492657485, 'multinomial', 'sag')\n",
      "{'C': 0.1, 'multi_class': 'multinomial', 'solver': 'sag'}\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:07:52] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.5404040404040404 1.00348789628708 XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, eta=0.01, gamma=0,\n",
      "              gpu_id=-1, importance_type='gain', interaction_constraints='',\n",
      "              lambda=0, learning_rate=0.00999999978, max_delta_step=0,\n",
      "              max_depth=2, min_child_weight=7, missing=nan,\n",
      "              monotone_constraints='()', n_estimators=500, n_jobs=4,\n",
      "              num_class=3, num_parallel_tree=1, objective='multi:softprob',\n",
      "              random_state=0, reg_alpha=0, reg_lambda=0, scale_pos_weight=None,\n",
      "              subsample=0.7, tree_method='exact', use_label_encoder=False,\n",
      "              validate_parameters=1, ...)\n",
      "0.5404040404040404 1.0027945953037745 SVC(gamma=0.001, probability=1)\n",
      "0.51010101010101 0.9897972337082978 LogisticRegression(C=0.1, multi_class='multinomial', solver='sag')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('scaler', StandardScaler()),\n",
       "                ('softmax',\n",
       "                 LogisticRegression(C=0.1, multi_class='multinomial',\n",
       "                                    solver='sag'))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Note parameters were tuned one, or two at time to cut down on computation time, so the grid does not reflect all values \n",
    "#tested\n",
    "\n",
    "def model_select_sklearn(param_grid, mods, X_tr, y_tr, X_val, y_val):\n",
    "    '''\n",
    "    For each model class under consideration, the hyperparameters are tuned to find the best model within\n",
    "    the class. The best models of each class are refit on the training and validation sets and the test error is\n",
    "    computed and the model with the highest test accuracy is chosen.\n",
    "    \n",
    "    Parameters:\n",
    "    param_grid (dic): maps each parameter to a list of values to be tested\n",
    "    mods (lst): list of multiclass classifiers\n",
    "    Xtr (np.array): training data\n",
    "    ytr (np.array): 1D array of training labels\n",
    "    Xval (np.array): validation data\n",
    "    yval (np.array): 1D array of validation labels\n",
    "    \n",
    "    Returns:\n",
    "    best_mod (obj): the model with the highest test accuracy\n",
    "    '''\n",
    "    optimal_mods = []\n",
    "    for name, mod in mods:\n",
    "        fit_params = {}\n",
    "        if name == 'xgb':\n",
    "            fit_params = {'clf__early_stopping_rounds': 20, 'clf__eval_set': [(X_val.values, y_val.values)], \n",
    "                          'clf__eval_metric':['merror','mlogloss'], 'clf__verbose':False}\n",
    "        val_scores, best_params = tune_hyperparams(mod, X_tr, y_tr, X_val, y_val, param_grids[name], fit_params)\n",
    "        print(best_params)\n",
    "        pipe = Pipeline(steps=[('scaler', preprocessing.StandardScaler()), (name, mod.set_params(**best_params))])\n",
    "        optimal_mods.append(pipe)\n",
    "    plot_xgb(optimal_mods[0]['xgb'])\n",
    "    top_logloss = np.inf\n",
    "    for mod in optimal_mods:\n",
    "        mod.fit(pd.concat((X_tr, X_val)), pd.concat((y_tr, y_val)))  #refit best models on training and validation sets\n",
    "        test_acc = mod.score(X_tst, y_tst)\n",
    "        test_logloss = log_loss(y_tst, mod.predict_proba(X_tst), labels=y_tst)\n",
    "        print(test_acc, test_logloss, mod[1])\n",
    "        if test_logloss <= top_logloss:\n",
    "            best_mod = mod\n",
    "            top_logloss = test_logloss\n",
    "    \n",
    "    return best_mod\n",
    "\n",
    "\n",
    "def plot_xgb(mod):\n",
    "    '''\n",
    "    Plots the validation error at each epoch during the training of an xgboost model\n",
    "    '''\n",
    "    fig, ax = plt.subplots(1,2)\n",
    "    eval_res = mod.evals_result()\n",
    "    ax[0].plot(range(0, len(eval_res['validation_0']['mlogloss'])), eval_res['validation_0']['mlogloss'])\n",
    "    ax[1].plot(range(0, len(eval_res['validation_0']['merror'])), eval_res['validation_0']['merror'])\n",
    "    ax[0].set(xlabel = 'Training Rounds', ylabel = 'Log Loss')\n",
    "    ax[1].set(xlabel='Training Rounds', ylabel='Classification Error')\n",
    "    ax[0].set_title('Log Loss on Validation Set')\n",
    "    ax[1].set_title('Classification Error on Validation Set')\n",
    "    plt.tight_layout()\n",
    "    plt.show()   \n",
    "\n",
    "\n",
    "param_grids = {'xgb': \n",
    "               {'subsample': [.7] , \n",
    "                'gamma': [0],\n",
    "                'lambda': [0], \n",
    "                'eta': [.01], 'n_estimators': [500],\n",
    "                'min_child_weight': [7], 'max_depth': [2],\n",
    "                'objective': ['multi:softmax'],\n",
    "                'num_class': [3] \n",
    "               },\n",
    "               'svc':\n",
    "               {'C': np.logspace(0,3,4), 'gamma': np.geomspace(1e-3,1,5), 'kernel':['rbf'], 'probability':[1]},\n",
    "               'softmax': \n",
    "               {'C': np.geomspace(1e-3, 1e-1, 500), 'multi_class': ['multinomial'], 'solver': ['sag']} \n",
    "            }\n",
    "mods = [('xgb', XGBClassifier(use_label_encoder=False)), ('svc', SVC()), ('softmax', LogisticRegression())]\n",
    "\n",
    "best_mod_sklearn = model_select_sklearn(param_grids, mods, X_tr, y_tr, X_val, y_val)\n",
    "best_mod_sklearn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from ray import tune\n",
    "import torchvision.transforms as transforms\n",
    "from functools import partial\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "== Status ==<br>Memory usage on this node: 1.0/12.3 GiB<br>Using AsyncHyperBand: num_stopped=97\n",
       "Bracket: Iter 64.000: -0.9104125499725342 | Iter 16.000: -0.9164682626724243 | Iter 4.000: -0.9291944801807404 | Iter 1.000: -0.9743205457925797<br>Resources requested: 0/4 CPUs, 0/0 GPUs, 0.0/7.13 GiB heap, 0.0/2.44 GiB objects<br>Result logdir: /home/swayam/ray_results/DEFAULT_2021-05-06_18-07-59<br>Number of trials: 100/100 (100 TERMINATED)<br><table>\n",
       "<thead>\n",
       "<tr><th>Trial name         </th><th>status    </th><th>loc  </th><th>activation             </th><th style=\"text-align: right;\">  batch</th><th style=\"text-align: right;\">  depth</th><th style=\"text-align: right;\">  epochs</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">     prob</th><th style=\"text-align: right;\">  weight_decay</th><th style=\"text-align: right;\">  width</th><th style=\"text-align: right;\">    loss</th><th style=\"text-align: right;\">     acc</th><th style=\"text-align: right;\">  training_iteration</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>DEFAULT_849f2_00000</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.0049516  </td><td style=\"text-align: right;\">0.0786896</td><td style=\"text-align: right;\">   0.000583578</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.914671</td><td style=\"text-align: right;\">0.585859</td><td style=\"text-align: right;\">                  75</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00001</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.00527951 </td><td style=\"text-align: right;\">0.101202 </td><td style=\"text-align: right;\">   0.000715286</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">0.946856</td><td style=\"text-align: right;\">0.570707</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00002</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000969036</td><td style=\"text-align: right;\">0.226066 </td><td style=\"text-align: right;\">   0.000129504</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">1.03405 </td><td style=\"text-align: right;\">0.494949</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00003</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.0029182  </td><td style=\"text-align: right;\">0.238349 </td><td style=\"text-align: right;\">   0.000540822</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.949633</td><td style=\"text-align: right;\">0.590909</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00004</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00285815 </td><td style=\"text-align: right;\">0.123846 </td><td style=\"text-align: right;\">   0.000488357</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">0.931532</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00005</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.0409739  </td><td style=\"text-align: right;\">0.23311  </td><td style=\"text-align: right;\">   0.000508695</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">1.10722 </td><td style=\"text-align: right;\">0.388889</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00006</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00118552 </td><td style=\"text-align: right;\">0.0919049</td><td style=\"text-align: right;\">   0.000116877</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.03823 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00007</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.0991656  </td><td style=\"text-align: right;\">0.106308 </td><td style=\"text-align: right;\">   0.000403937</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.04524 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00008</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000468415</td><td style=\"text-align: right;\">0.0818029</td><td style=\"text-align: right;\">   0.000637406</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.07351 </td><td style=\"text-align: right;\">0.5     </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00009</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000901746</td><td style=\"text-align: right;\">0.0926957</td><td style=\"text-align: right;\">   0.000986657</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.00565 </td><td style=\"text-align: right;\">0.50505 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00010</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00285738 </td><td style=\"text-align: right;\">0.0871296</td><td style=\"text-align: right;\">   0.000694117</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">0.9708  </td><td style=\"text-align: right;\">0.585859</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00011</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00242815 </td><td style=\"text-align: right;\">0.0805689</td><td style=\"text-align: right;\">   0.000254579</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.961728</td><td style=\"text-align: right;\">0.545455</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00012</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.0663692  </td><td style=\"text-align: right;\">0.190388 </td><td style=\"text-align: right;\">   0.000417216</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.03887 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00013</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000146992</td><td style=\"text-align: right;\">0.249938 </td><td style=\"text-align: right;\">   0.000169502</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.15318 </td><td style=\"text-align: right;\">0.19697 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00014</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.00395578 </td><td style=\"text-align: right;\">0.10172  </td><td style=\"text-align: right;\">   0.000892782</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.97474 </td><td style=\"text-align: right;\">0.545455</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00015</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0166331  </td><td style=\"text-align: right;\">0.203392 </td><td style=\"text-align: right;\">   0.000782575</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.03974 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00016</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0127525  </td><td style=\"text-align: right;\">0.104425 </td><td style=\"text-align: right;\">   1.24884e-05</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">0.958552</td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00017</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.000604278</td><td style=\"text-align: right;\">0.202522 </td><td style=\"text-align: right;\">   0.000610306</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.04819 </td><td style=\"text-align: right;\">0.414141</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00018</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00160924 </td><td style=\"text-align: right;\">0.227795 </td><td style=\"text-align: right;\">   0.000950986</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.963569</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00019</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00329284 </td><td style=\"text-align: right;\">0.229713 </td><td style=\"text-align: right;\">   0.000527623</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.01892 </td><td style=\"text-align: right;\">0.545455</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00020</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00119306 </td><td style=\"text-align: right;\">0.186286 </td><td style=\"text-align: right;\">   0.000812442</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.07357 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00021</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.00386003 </td><td style=\"text-align: right;\">0.204847 </td><td style=\"text-align: right;\">   0.000374866</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">0.998472</td><td style=\"text-align: right;\">0.555556</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00022</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0164708  </td><td style=\"text-align: right;\">0.114977 </td><td style=\"text-align: right;\">   9.66827e-05</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.965741</td><td style=\"text-align: right;\">0.565657</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00023</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000558542</td><td style=\"text-align: right;\">0.135169 </td><td style=\"text-align: right;\">   0.00082589 </td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">1.10269 </td><td style=\"text-align: right;\">0.318182</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00024</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00131954 </td><td style=\"text-align: right;\">0.147562 </td><td style=\"text-align: right;\">   0.000672957</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.977323</td><td style=\"text-align: right;\">0.565657</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00025</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000245996</td><td style=\"text-align: right;\">0.157136 </td><td style=\"text-align: right;\">   0.000382603</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.09582 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00026</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0275849  </td><td style=\"text-align: right;\">0.17624  </td><td style=\"text-align: right;\">   0.000768457</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.993933</td><td style=\"text-align: right;\">0.555556</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00027</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00718445 </td><td style=\"text-align: right;\">0.230848 </td><td style=\"text-align: right;\">   0.000193418</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.962095</td><td style=\"text-align: right;\">0.545455</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00028</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00121528 </td><td style=\"text-align: right;\">0.184949 </td><td style=\"text-align: right;\">   0.000505224</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">1.10801 </td><td style=\"text-align: right;\">0.212121</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00029</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0254667  </td><td style=\"text-align: right;\">0.0770948</td><td style=\"text-align: right;\">   0.000622813</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">0.957081</td><td style=\"text-align: right;\">0.60101 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00030</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00490728 </td><td style=\"text-align: right;\">0.168235 </td><td style=\"text-align: right;\">   0.000372433</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">0.957503</td><td style=\"text-align: right;\">0.535354</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00031</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00624378 </td><td style=\"text-align: right;\">0.0966857</td><td style=\"text-align: right;\">   0.000823419</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.969105</td><td style=\"text-align: right;\">0.555556</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00032</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00623364 </td><td style=\"text-align: right;\">0.230988 </td><td style=\"text-align: right;\">   0.000344371</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.978747</td><td style=\"text-align: right;\">0.60101 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00033</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00189673 </td><td style=\"text-align: right;\">0.121087 </td><td style=\"text-align: right;\">   0.000755016</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">0.924558</td><td style=\"text-align: right;\">0.580808</td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00034</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000844961</td><td style=\"text-align: right;\">0.211957 </td><td style=\"text-align: right;\">   0.000291609</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.0722  </td><td style=\"text-align: right;\">0.434343</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00035</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00494361 </td><td style=\"text-align: right;\">0.199578 </td><td style=\"text-align: right;\">   0.000546453</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">0.931831</td><td style=\"text-align: right;\">0.580808</td><td style=\"text-align: right;\">                  16</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00036</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.0480445  </td><td style=\"text-align: right;\">0.237214 </td><td style=\"text-align: right;\">   1.92094e-05</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">0.982816</td><td style=\"text-align: right;\">0.489899</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00037</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00397079 </td><td style=\"text-align: right;\">0.212294 </td><td style=\"text-align: right;\">   0.000235497</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">1.00927 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00038</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000182893</td><td style=\"text-align: right;\">0.134237 </td><td style=\"text-align: right;\">   0.000293056</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.0989  </td><td style=\"text-align: right;\">0.287879</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00039</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000111131</td><td style=\"text-align: right;\">0.145202 </td><td style=\"text-align: right;\">   0.000578594</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.19584 </td><td style=\"text-align: right;\">0.20202 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00040</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00286585 </td><td style=\"text-align: right;\">0.106586 </td><td style=\"text-align: right;\">   0.00067002 </td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.00761 </td><td style=\"text-align: right;\">0.489899</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00041</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00935714 </td><td style=\"text-align: right;\">0.184256 </td><td style=\"text-align: right;\">   0.000985219</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">0.991245</td><td style=\"text-align: right;\">0.550505</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00042</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000471472</td><td style=\"text-align: right;\">0.128649 </td><td style=\"text-align: right;\">   0.000274654</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">1.12058 </td><td style=\"text-align: right;\">0.267677</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00043</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000915303</td><td style=\"text-align: right;\">0.080986 </td><td style=\"text-align: right;\">   0.000960816</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.05267 </td><td style=\"text-align: right;\">0.424242</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00044</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00225289 </td><td style=\"text-align: right;\">0.107439 </td><td style=\"text-align: right;\">   0.000311553</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.958462</td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00045</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00426548 </td><td style=\"text-align: right;\">0.154846 </td><td style=\"text-align: right;\">   0.000721083</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">0.981809</td><td style=\"text-align: right;\">0.494949</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00046</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00684906 </td><td style=\"text-align: right;\">0.0848441</td><td style=\"text-align: right;\">   0.000722759</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">0.939762</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                  25</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00047</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000449967</td><td style=\"text-align: right;\">0.144947 </td><td style=\"text-align: right;\">   0.000410979</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.04127 </td><td style=\"text-align: right;\">0.550505</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00048</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00135933 </td><td style=\"text-align: right;\">0.144941 </td><td style=\"text-align: right;\">   2.08695e-05</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">1.04671 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00049</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0498315  </td><td style=\"text-align: right;\">0.0791906</td><td style=\"text-align: right;\">   0.000818377</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.05442 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00050</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000326383</td><td style=\"text-align: right;\">0.112429 </td><td style=\"text-align: right;\">   0.000367467</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.08705 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00051</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00836019 </td><td style=\"text-align: right;\">0.142096 </td><td style=\"text-align: right;\">   0.000462991</td><td style=\"text-align: right;\">     12</td><td style=\"text-align: right;\">0.945249</td><td style=\"text-align: right;\">0.580808</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00052</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0224673  </td><td style=\"text-align: right;\">0.0956395</td><td style=\"text-align: right;\">   3.8916e-05 </td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.04818 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00053</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000316007</td><td style=\"text-align: right;\">0.102466 </td><td style=\"text-align: right;\">   0.000579722</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.11457 </td><td style=\"text-align: right;\">0.282828</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00054</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000481396</td><td style=\"text-align: right;\">0.218207 </td><td style=\"text-align: right;\">   0.000336151</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.1491  </td><td style=\"text-align: right;\">0.469697</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00055</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0559477  </td><td style=\"text-align: right;\">0.0827036</td><td style=\"text-align: right;\">   0.000251579</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">1.05177 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00056</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000222515</td><td style=\"text-align: right;\">0.23919  </td><td style=\"text-align: right;\">   0.000628417</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">1.1387  </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00057</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0032457  </td><td style=\"text-align: right;\">0.093479 </td><td style=\"text-align: right;\">   0.000473633</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.02495 </td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00058</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00394353 </td><td style=\"text-align: right;\">0.102594 </td><td style=\"text-align: right;\">   0.000143892</td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">0.973064</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00059</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0699408  </td><td style=\"text-align: right;\">0.0845194</td><td style=\"text-align: right;\">   0.000869289</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.7664  </td><td style=\"text-align: right;\">0.489899</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00060</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0276578  </td><td style=\"text-align: right;\">0.142296 </td><td style=\"text-align: right;\">   0.000477328</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">0.978249</td><td style=\"text-align: right;\">0.570707</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00061</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000234162</td><td style=\"text-align: right;\">0.22257  </td><td style=\"text-align: right;\">   0.000227778</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.14358 </td><td style=\"text-align: right;\">0.30303 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00062</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.00122495 </td><td style=\"text-align: right;\">0.224554 </td><td style=\"text-align: right;\">   0.000883041</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.04164 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00063</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.000294288</td><td style=\"text-align: right;\">0.223029 </td><td style=\"text-align: right;\">   0.000869721</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.09354 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00064</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0827533  </td><td style=\"text-align: right;\">0.127965 </td><td style=\"text-align: right;\">   0.000894525</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.04352 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00065</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00242216 </td><td style=\"text-align: right;\">0.155993 </td><td style=\"text-align: right;\">   7.66073e-05</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.03804 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00066</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.00808313 </td><td style=\"text-align: right;\">0.211099 </td><td style=\"text-align: right;\">   0.00099621 </td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.00973 </td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00067</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00153289 </td><td style=\"text-align: right;\">0.229172 </td><td style=\"text-align: right;\">   0.000904251</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.999741</td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00068</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.059072   </td><td style=\"text-align: right;\">0.198461 </td><td style=\"text-align: right;\">   0.000249472</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.03965 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00069</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.00050884 </td><td style=\"text-align: right;\">0.210046 </td><td style=\"text-align: right;\">   0.000355367</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.04601 </td><td style=\"text-align: right;\">0.525253</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00070</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.017569   </td><td style=\"text-align: right;\">0.184749 </td><td style=\"text-align: right;\">   0.000445407</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">1.03093 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00071</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.0856376  </td><td style=\"text-align: right;\">0.203656 </td><td style=\"text-align: right;\">   5.7691e-05 </td><td style=\"text-align: right;\">      9</td><td style=\"text-align: right;\">1.04325 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00072</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.0464854  </td><td style=\"text-align: right;\">0.22374  </td><td style=\"text-align: right;\">   0.000602667</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.0414  </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00073</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000144738</td><td style=\"text-align: right;\">0.218477 </td><td style=\"text-align: right;\">   0.000559422</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.14844 </td><td style=\"text-align: right;\">0.19697 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00074</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000133577</td><td style=\"text-align: right;\">0.108553 </td><td style=\"text-align: right;\">   0.000188684</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.1797  </td><td style=\"text-align: right;\">0.19697 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00075</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000317554</td><td style=\"text-align: right;\">0.241709 </td><td style=\"text-align: right;\">   0.000316087</td><td style=\"text-align: right;\">     14</td><td style=\"text-align: right;\">1.03273 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00076</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.0787211  </td><td style=\"text-align: right;\">0.24944  </td><td style=\"text-align: right;\">   0.000812299</td><td style=\"text-align: right;\">     10</td><td style=\"text-align: right;\">1.05138 </td><td style=\"text-align: right;\">0.474747</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00077</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000567877</td><td style=\"text-align: right;\">0.100649 </td><td style=\"text-align: right;\">   0.000802165</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">1.02938 </td><td style=\"text-align: right;\">0.550505</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00078</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000681198</td><td style=\"text-align: right;\">0.0925824</td><td style=\"text-align: right;\">   0.000297186</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.03947 </td><td style=\"text-align: right;\">0.530303</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00079</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.00332949 </td><td style=\"text-align: right;\">0.147001 </td><td style=\"text-align: right;\">   0.000462917</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">1.04382 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00080</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00044177 </td><td style=\"text-align: right;\">0.170186 </td><td style=\"text-align: right;\">   0.0009685  </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.0635  </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00081</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.00258966 </td><td style=\"text-align: right;\">0.194114 </td><td style=\"text-align: right;\">   0.000756825</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">0.929738</td><td style=\"text-align: right;\">0.570707</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00082</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0275408  </td><td style=\"text-align: right;\">0.116019 </td><td style=\"text-align: right;\">   0.000731705</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.990373</td><td style=\"text-align: right;\">0.545455</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00083</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0405771  </td><td style=\"text-align: right;\">0.114274 </td><td style=\"text-align: right;\">   0.000881827</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">0.934454</td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00084</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.00424667 </td><td style=\"text-align: right;\">0.248869 </td><td style=\"text-align: right;\">   0.000126912</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">0.997429</td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00085</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.000111662</td><td style=\"text-align: right;\">0.248037 </td><td style=\"text-align: right;\">   0.000473353</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.05675 </td><td style=\"text-align: right;\">0.383838</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00086</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0328959  </td><td style=\"text-align: right;\">0.142704 </td><td style=\"text-align: right;\">   5.87297e-06</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.04084 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00087</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000741352</td><td style=\"text-align: right;\">0.220618 </td><td style=\"text-align: right;\">   0.000498741</td><td style=\"text-align: right;\">      6</td><td style=\"text-align: right;\">1.02891 </td><td style=\"text-align: right;\">0.565657</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00088</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.000449728</td><td style=\"text-align: right;\">0.181453 </td><td style=\"text-align: right;\">   0.000120787</td><td style=\"text-align: right;\">      5</td><td style=\"text-align: right;\">1.04027 </td><td style=\"text-align: right;\">0.434343</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00089</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      1</td><td style=\"text-align: right;\">      75</td><td style=\"text-align: right;\">0.0130962  </td><td style=\"text-align: right;\">0.160674 </td><td style=\"text-align: right;\">   0.000790739</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">0.94    </td><td style=\"text-align: right;\">0.560606</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00090</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      10</td><td style=\"text-align: right;\">0.000155824</td><td style=\"text-align: right;\">0.160784 </td><td style=\"text-align: right;\">   0.000429651</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.10204 </td><td style=\"text-align: right;\">0.247475</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00091</td><td>TERMINATED</td><td>     </td><td>ReLU()                 </td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.000686632</td><td style=\"text-align: right;\">0.224773 </td><td style=\"text-align: right;\">   0.000800535</td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">1.04621 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00092</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.000587183</td><td style=\"text-align: right;\">0.106756 </td><td style=\"text-align: right;\">   0.000615059</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.11792 </td><td style=\"text-align: right;\">0.19697 </td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00093</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">     150</td><td style=\"text-align: right;\">0.0685833  </td><td style=\"text-align: right;\">0.193527 </td><td style=\"text-align: right;\">   0.000371027</td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.03518 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00094</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0068547  </td><td style=\"text-align: right;\">0.179896 </td><td style=\"text-align: right;\">   0.000882316</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">0.91767 </td><td style=\"text-align: right;\">0.575758</td><td style=\"text-align: right;\">                  25</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00095</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      40</td><td style=\"text-align: right;\">0.000322664</td><td style=\"text-align: right;\">0.10695  </td><td style=\"text-align: right;\">   0.00053577 </td><td style=\"text-align: right;\">      7</td><td style=\"text-align: right;\">1.05514 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00096</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.000121846</td><td style=\"text-align: right;\">0.220022 </td><td style=\"text-align: right;\">   0.000527408</td><td style=\"text-align: right;\">      8</td><td style=\"text-align: right;\">1.05306 </td><td style=\"text-align: right;\">0.469697</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00097</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">      25</td><td style=\"text-align: right;\">0.0358888  </td><td style=\"text-align: right;\">0.222957 </td><td style=\"text-align: right;\">   0.000467194</td><td style=\"text-align: right;\">     11</td><td style=\"text-align: right;\">0.997193</td><td style=\"text-align: right;\">0.550505</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00098</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      2</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.00391223 </td><td style=\"text-align: right;\">0.169943 </td><td style=\"text-align: right;\">   0.00052307 </td><td style=\"text-align: right;\">     13</td><td style=\"text-align: right;\">0.946617</td><td style=\"text-align: right;\">0.590909</td><td style=\"text-align: right;\">                   4</td></tr>\n",
       "<tr><td>DEFAULT_849f2_00099</td><td>TERMINATED</td><td>     </td><td>PReLU(num_parameters=1)</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      4</td><td style=\"text-align: right;\">      50</td><td style=\"text-align: right;\">0.0317964  </td><td style=\"text-align: right;\">0.23023  </td><td style=\"text-align: right;\">   0.000790544</td><td style=\"text-align: right;\">      3</td><td style=\"text-align: right;\">1.03259 </td><td style=\"text-align: right;\">0.484848</td><td style=\"text-align: right;\">                   1</td></tr>\n",
       "</tbody>\n",
       "</table><br><br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-06 18:13:57,795\tINFO tune.py:450 -- Total run time: 361.74 seconds (358.40 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'depth': 2, 'width': 9, 'activation': ReLU(), 'epochs': 75, 'batch': 4, 'lr': 0.004951597989418886, 'prob': 0.07868960807634182, 'weight_decay': 0.0005835784937656156}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/torch/autograd/__init__.py:130: UserWarning: CUDA initialization: Found no NVIDIA driver on your system. Please check that you have an NVIDIA GPU and installed a driver from http://www.nvidia.com/Download/index.aspx (Triggered internally at  /pytorch/c10/cuda/CUDAFunctions.cpp:100.)\n",
      "  Variable._execution_engine.run_backward(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.5303)\n",
      "0.9999739527702332\n"
     ]
    }
   ],
   "source": [
    "class Net(nn.Module):\n",
    "    '''\n",
    "    Defines a feedforward neural network where each layer is a compostion of an affine function with \n",
    "    a nonlinear activation function that is applied elementwise. Dropout is applied to each layer except the output\n",
    "    layer for regularization purposes.\n",
    "    \n",
    "    Attributes:\n",
    "    linears: the linear layers\n",
    "    output: the ouput layer\n",
    "    activation: the activation function\n",
    "    dropout: applies dropout\n",
    "    '''\n",
    "    def __init__(self, depth, width, activation, prob, num_classes):\n",
    "        '''\n",
    "        Constructor\n",
    "        \n",
    "        Parameters:\n",
    "        depth (int): the number of layers\n",
    "        width (int): the number of units in each layer\n",
    "        activation (torch.nn): the activation function (same one used for each layer)\n",
    "        prob (float): the probability with which a neuron has its outgoing connections killed in a dropout layer\n",
    "        num_classes (int): the number of classes in our classification problem\n",
    "            \n",
    "        '''\n",
    "        super(Net, self).__init__()\n",
    "        self.linears = nn.ModuleList([nn.Linear(width, width) if i!= 0 else nn.Linear(\n",
    "            NUM_FEATS, width) for i in range(depth)])\n",
    "        self.output = nn.Linear(width, num_classes)\n",
    "        self.activation = activation\n",
    "        #self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(prob) \n",
    "    \n",
    "    def forward(self, x):\n",
    "        for l in self.linears:\n",
    "            x = self.dropout(self.activation(l(x)))\n",
    "        x = self.output(x)\n",
    "        #x = self.softmax(x)\n",
    "        \n",
    "        return x\n",
    "\n",
    "class MatchData(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        super(MatchData, self).__init__()\n",
    "        self.X = torch.tensor(X.values, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y.values, dtype=torch.int64)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        return self.X[index,], self.y[index]\n",
    "\n",
    "\n",
    "def normalize(X, mu, sd):\n",
    "    '''\n",
    "    Normalizes X by subtracting MU and dividing by SD\n",
    "    '''\n",
    "    return (X - mu) / sd\n",
    "\n",
    "\n",
    "def compute_acc(labels, outputs):\n",
    "    '''\n",
    "    Converts raw ouput from network to a class prediction and computes accuracy relative to \n",
    "    true labels\n",
    "    '''\n",
    "    preds = torch.argmax(outputs.data, 1)\n",
    "    \n",
    "    return (preds == labels).sum() / labels.size(0)\n",
    "\n",
    "\n",
    "def train_nn(param_grid, criterion=None, X_tr=None, y_tr=None, X_val=None, y_val=None, checkpoint_dir=None):\n",
    "    '''\n",
    "    Trains neural net with a particular configuration of hyperparameters given by the param grid.\n",
    "    At each epoch the validation loss and accuracy is reported to ray tune.\n",
    "    \n",
    "    Parameters:\n",
    "    param_grid (dic): maps hyperparameters to the particular value being tested\n",
    "    Xtr (np.array): training data\n",
    "    ytr (np.array): 1D array of training labels\n",
    "    Xval (np.array): validation data\n",
    "    yval (np.array): 1D array of validation labels\n",
    "    '''\n",
    "    net = Net(param_grid['depth'], param_grid['width'], param_grid['activation'], param_grid['prob'], NUM_CLASSES)\n",
    "    #criterion = nn.CrossEntropyLoss()\n",
    "    if param_grid['activation'] == 'nn.PReLU()':\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': net.activation.parameters(), 'weight_decay':0},\n",
    "            {'params': net.linears.parameters()},\n",
    "            {'params': net.output.parameters()}\n",
    "        ],\n",
    "            lr=param_grid['lr'], weight_decay=param_grid['weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(net.parameters(), lr=param_grid['lr'],\n",
    "                         weight_decay= param_grid['weight_decay'])\n",
    "    if checkpoint_dir:\n",
    "        mod_state, optim_state = torch.load(os.path.join(checkpoint_dir, 'checkpoint'))\n",
    "        net.load_state_dict(mod_state)\n",
    "        optimizer.load_state_dict(optim_state)\n",
    "    trainset = MatchData(X_tr, y_tr)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=param_grid['batch'], \n",
    "                                              shuffle=True)\n",
    "    \n",
    "    for epoch in range(param_grid['epochs']):\n",
    "        train_loop(trainloader, optimizer, criterion, net)\n",
    "        with torch.no_grad():\n",
    "            net.eval()\n",
    "            val_labels = torch.tensor(y_val.values, dtype=torch.int64)\n",
    "            val_outputs = net(torch.tensor(X_val.values, dtype=torch.float32))\n",
    "            val_loss = criterion(val_outputs, val_labels).item()\n",
    "            val_acc = compute_acc(val_labels, val_outputs)\n",
    "            net.train()\n",
    "        with tune.checkpoint_dir(epoch) as checkpoint_dir:\n",
    "            path = os.path.join(checkpoint_dir, 'checkpoint')\n",
    "            torch.save((net.state_dict(), optimizer.state_dict()), path)\n",
    "            \n",
    "        tune.report(loss=val_loss, acc=val_acc)\n",
    "\n",
    "def train_loop(trainloader, optimizer, criterion, net):\n",
    "    '''\n",
    "    Loops over training data and updates the weights according the optimzation algorithm\n",
    "    \n",
    "    Parameters:\n",
    "    trainloader: allows for iterating over the training set in batches\n",
    "    optimizer: implements optimzation algorithm used, controls weight update\n",
    "    criterion: defines the loss function that is being optimized\n",
    "    net: the model \n",
    "    '''\n",
    "    \n",
    "    running_loss = 0\n",
    "    for idx, batch in enumerate(trainloader):\n",
    "        inputs, labels = batch\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        #print(epoch, running_loss)\n",
    "\n",
    "\n",
    "        \n",
    "def model_select_nn(param_grid, criterion, scheduler, num_trials, X_tr, y_tr, X_val, y_val, X_tst, y_tst):\n",
    "    '''\n",
    "    Uses tune to draw samples of hyperparam configurations from the search space defined by \n",
    "    the parameter grid and fits a model for each sample. The model with the lowest validation loss\n",
    "    is chosen and is retrained on both the training and validation set. The test accuracy is reported.\n",
    "    \n",
    "    Parameters:\n",
    "    param_grid (dic): maps hyperparam to a distribution to draw samples from\n",
    "    scheduler: algorithm used to implement early stopping and peturb hyperparams\n",
    "    num_trials (int): the number of samples to draw\n",
    "    Xtr (np.array): training data\n",
    "    ytr (np.array): 1D array of training labels\n",
    "    Xval (np.array): validation data\n",
    "    yval (np.array): 1D array of validation labels\n",
    "    Xtst (np.array): test data\n",
    "    ytst (np.array): 1D array of test labels\n",
    "    '''\n",
    "    reporter = tune.JupyterNotebookReporter(metric_columns = ['loss', 'acc', 'training_iteration'], overwrite=1)\n",
    "    res = tune.run(partial(train_nn, criterion=criterion, X_tr=X_tr, y_tr=y_tr, X_val=X_val, y_val=y_val),\n",
    "             resources_per_trial={'cpu':4, 'gpu': 0},\n",
    "             config=param_grid,\n",
    "             scheduler=scheduler,\n",
    "             progress_reporter=reporter,\n",
    "             num_samples=num_trials)\n",
    "    best_trial = res.get_best_trial('loss', 'min')\n",
    "    print(best_trial.config)\n",
    "    best_mod = Net(best_trial.config['depth'], best_trial.config['width'], best_trial.config['activation'],\n",
    "                  best_trial.config['prob'], NUM_CLASSES)\n",
    "    #best_checkpoint_dir = best_trial.checkpoint.value\n",
    "    #mod_state, optim_state = torch.load(os.path.join(best_checkpoint_dir, 'checkpoint'))\n",
    "    #best_mod.load_state_dict(mod_state)\n",
    "    train_val_set = MatchData(pd.concat((X_tr, X_val)), pd.concat((y_tr, y_val)))\n",
    "    train_val_loader = torch.utils.data.DataLoader(train_val_set, batch_size=best_trial.config['batch'],\n",
    "                                                  shuffle=True)\n",
    "    \n",
    "    if best_trial.config['activation'] == 'nn.PReLU()':\n",
    "        optimizer = optim.Adam([\n",
    "            {'params': best_mod.activation.parameters(), 'weight_decay':0},\n",
    "            {'params': best_mod.linears.parameters()},\n",
    "            {'params': best_mod.output.parameters()}\n",
    "        ],\n",
    "            lr=best_trial.config['lr'], weight_decay=best_trial.config['weight_decay'])\n",
    "    else:\n",
    "        optimizer = optim.Adam(best_mod.parameters(), lr=best_trial.config['lr'],\n",
    "                         weight_decay=best_trial.config['weight_decay'])\n",
    "    \n",
    "    for epoch in range(best_trial.config['epochs']):\n",
    "        train_loop(train_val_loader, optimizer, criterion, best_mod)  \n",
    "    best_mod.eval()\n",
    "    with torch.no_grad():\n",
    "        test_labels = torch.tensor(y_tst.values, dtype=torch.int64)\n",
    "        test_outputs = best_mod(torch.tensor(X_tst.values, dtype=torch.float32))\n",
    "        print(compute_acc(test_labels, test_outputs))\n",
    "        print(criterion(test_outputs, test_labels).item())\n",
    "    \n",
    "    return best_mod\n",
    "\n",
    "\n",
    "MU = np.mean(X_tr)\n",
    "SD = np.sqrt(np.diag(np.cov(X_tr.T)))\n",
    "X_tr = normalize(X_tr, MU, SD)\n",
    "X_val = normalize(X_val, MU, SD)\n",
    "X_tst = normalize(X_tst, MU, SD)\n",
    "\n",
    "param_grid = {\n",
    "    'depth': tune.randint(1, 5),\n",
    "    'width': tune.randint(3, 15),\n",
    "    'activation': tune.choice([nn.ReLU(), nn.PReLU()]),\n",
    "    'epochs': tune.choice([10, 25, 40, 50, 75, 150]),\n",
    "    'batch': tune.choice([2**i for i in range(1, 4)]),\n",
    "    'lr': tune.loguniform(1e-4, 1e-1),\n",
    "    #'momentum': tune.uniform(.9, .99),\n",
    "    'prob': tune.uniform(.075,.25),\n",
    "    'weight_decay':tune.uniform(1e-6, 1e-3)\n",
    "}\n",
    "\n",
    "'''\n",
    "param_grid = {\n",
    "    'depth': tune.randint(5,7),\n",
    "    'width': tune.randint(8, 11),\n",
    "    'activation': tune.choice([nn.ReLU(), nn.PReLU()]),\n",
    "    'epochs': tune.choice([30, 40, 50, 75, 100 ,150]),\n",
    "    'batch': tune.choice([2**i for i in range(1,3)]),\n",
    "    'lr': tune.loguniform(1e-4, 1e-2),\n",
    "    #'momentum': tune.uniform(.95, .99),\n",
    "    'prob': tune.uniform(.05, .25),\n",
    "    'weight_decay': tune.uniform(1e-5, 1e-3)\n",
    "}\n",
    "'''\n",
    "scheduler = tune.schedulers.ASHAScheduler(metric = 'loss', mode='min')\n",
    "num_trials = 100\n",
    "loss = nn.CrossEntropyLoss()\n",
    "best_mod_nn = model_select_nn(param_grid, loss, scheduler, num_trials, X_tr, y_tr, X_val, y_val, X_tst, y_tst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_strat(row):\n",
    "    '''\n",
    "    Defines a simple betting strategy where 1 dollar is bet on the outcome with the highest probability\n",
    "    \n",
    "    Parameters: row containing prediction, true result and betting information\n",
    "    \n",
    "    Returns: 1 if bet is lost, and the payout given by the odds if won   \n",
    "    '''\n",
    "    if row[0] != row[1]:\n",
    "        return -1 \n",
    "    if row[0] == 'H':\n",
    "        return row[4]\n",
    "    elif row[0] == 'A':\n",
    "        return row[6]\n",
    "    else:\n",
    "        return row[5]\n",
    "\n",
    "MIN_PROB = .45\n",
    "FACTOR = 5\n",
    "def conservative_strat(row):\n",
    "    '''\n",
    "    Defines a betting strategy where a bet is placed only if the probability associated with the most likely class is\n",
    "    .5 or greater. If a bet is made, the wager is proportional to the product of the probability and some constant.\n",
    "    \n",
    "    Parameters: row containing prediction, true result and betting information\n",
    "    \n",
    "    Returns: 1 if bet is lost, and the payout given by the odds if won    \n",
    "    '''\n",
    "    if row[2] >= MIN_PROB:\n",
    "        wager = round(row[2] * FACTOR, 2)\n",
    "        if row[0] != row[1]:\n",
    "            return -wager\n",
    "        elif row[0] == 'H':\n",
    "            return row[4] * wager\n",
    "        elif row[0] == 'A':\n",
    "            return row[6] * wager\n",
    "        else:\n",
    "            return row[5] * wager\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226.86999999999995\n",
      "    ypred ytest  predicted_prob  index  B365H  B365D  B365A  winnings\n",
      "0       H     A        0.540128    947   1.22   7.00  15.00     -1.00\n",
      "1       H     H        0.522692    577   1.75   3.50   6.00      1.75\n",
      "2       H     H        0.518012     85   2.20   3.30   3.75      2.20\n",
      "3       H     D        0.535021    242   2.00   3.40   4.33     -1.00\n",
      "4       H     H        0.578267    698   1.18   8.50  17.00      1.18\n",
      "..    ...   ...             ...    ...    ...    ...    ...       ...\n",
      "193     H     A        0.431296    106  10.00   5.75   1.33     -1.00\n",
      "194     H     H        0.546911    270   2.55   3.20   2.80      2.55\n",
      "195     H     A        0.455690    860   1.28   6.00  12.00     -1.00\n",
      "196     H     H        0.556703    435   5.25   4.33   1.66      5.25\n",
      "197     H     A        0.483278    102   5.25   4.00   1.70     -1.00\n",
      "\n",
      "[198 rows x 8 columns]\n",
      "ypred                    H\n",
      "ytest                    H\n",
      "predicted_prob    0.459366\n",
      "index                  546\n",
      "B365H                   12\n",
      "B365D                 4.75\n",
      "B365A                  1.3\n",
      "winnings                12\n",
      "Name: 38, dtype: object\n",
      "596.7302\n",
      "    ypred ytest  predicted_prob  index  B365H  B365D  B365A  winnings\n",
      "0       H     A        0.540128    947   1.22   7.00  15.00   -2.7000\n",
      "1       H     H        0.522692    577   1.75   3.50   6.00    4.5675\n",
      "2       H     H        0.518012     85   2.20   3.30   3.75    5.6980\n",
      "3       H     D        0.535021    242   2.00   3.40   4.33   -2.6800\n",
      "4       H     H        0.578267    698   1.18   8.50  17.00    3.4102\n",
      "..    ...   ...             ...    ...    ...    ...    ...       ...\n",
      "193     H     A        0.431296    106  10.00   5.75   1.33    0.0000\n",
      "194     H     H        0.546911    270   2.55   3.20   2.80    6.9615\n",
      "195     H     A        0.455690    860   1.28   6.00  12.00   -2.2800\n",
      "196     H     H        0.556703    435   5.25   4.33   1.66   14.5950\n",
      "197     H     A        0.483278    102   5.25   4.00   1.70   -2.4200\n",
      "\n",
      "[198 rows x 8 columns]\n",
      "ypred                    H\n",
      "ytest                    H\n",
      "predicted_prob    0.459366\n",
      "index                  546\n",
      "B365H                   12\n",
      "B365D                 4.75\n",
      "B365A                  1.3\n",
      "winnings              27.6\n",
      "Name: 38, dtype: object\n"
     ]
    }
   ],
   "source": [
    "ypred = best_mod_sklearn.predict(X_tst)\n",
    "ys = np.vstack((ypred, y_tst))\n",
    "ys = np.where(ys==2,'H', np.where(ys==0, 'A', 'D')) #convert back to original labels\n",
    "probs = np.max(best_mod_sklearn.predict_proba(X_tst), axis=1)\n",
    "pred_target_prob = pd.DataFrame(np.vstack((ys, probs)).T, columns=['ypred', 'ytest', 'predicted_prob'])\n",
    "pred_target_prob = pred_target_prob.astype({'predicted_prob': float})\n",
    "odds = data_full.iloc[10 * PREV_GAMES:,23:26].reset_index(drop=True).iloc[y_tst.index].reset_index()\n",
    "winnings_dat = pd.concat((pred_target_prob, odds), axis=1)\n",
    "#print(winnings_dat)\n",
    "\n",
    "for strat in [simple_strat, conservative_strat]:\n",
    "    winnings_dat['winnings'] = winnings_dat.apply(strat, axis=1)\n",
    "    print(sum(winnings_dat['winnings']))\n",
    "    print(winnings_dat)\n",
    "    print(winnings_dat.iloc[winnings_dat['winnings'].idxmax(),:])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
